{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Heart Disease Prediction**  \n",
    "\n",
    "## **Feature Engineering**  \n",
    "This notebook focuses on performing feature engineering to prepare the dataset for model training. The goal is to clean, transform, and modify the data to ensure its predictive power.  \n",
    "\n",
    "### **Feature Engineering Process**  \n",
    "- **Data Cleaning:** Handling missing values, removing duplicates, and addressing outliers if necessary.  \n",
    "- **Feature Selection:** Eliminating redundant or uninformative attributes.  \n",
    "- **Feature Engineering:** Transforming variables, discretizing continuous features, creating new meaningful attributes, and applying mathematical transformations where appropriate.  \n",
    "- **Feature Scaling:** Standardizing or normalizing numerical features.  \n",
    "- **Encoding:** Converting categorical variables into numerical representations suitable for modeling.  \n",
    "\n",
    "All transformations will be implemented using **scikit-learn pipelines** to ensure a structured and reproducible workflow. \n",
    "\n",
    "`Simón Correa Marín`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import Libraries and Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base libraries for data science\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().resolve().parents[0] / \"data\"\n",
    "\n",
    "hd_df = pd.read_parquet(\n",
    "    DATA_DIR / \"02_intermediate/hd_type_fixed.parquet\", engine=\"pyarrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version:  2.2.3\n",
      "sklearn version:  1.6.1\n"
     ]
    }
   ],
   "source": [
    "# print library version for reproducibility\n",
    "\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"sklearn version: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6848 entries, 0 to 6847\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   rest_ecg    6392 non-null   category\n",
      " 1   ca          6479 non-null   float64 \n",
      " 2   thal        6552 non-null   category\n",
      " 3   max_hr      6453 non-null   float64 \n",
      " 4   exang       6848 non-null   bool    \n",
      " 5   old_peak    6763 non-null   float64 \n",
      " 6   chol        6643 non-null   float64 \n",
      " 7   rest_bp     6655 non-null   float64 \n",
      " 8   chest_pain  6648 non-null   category\n",
      " 9   disease     6848 non-null   bool    \n",
      " 10  sex         6692 non-null   category\n",
      " 11  fbs         6848 non-null   bool    \n",
      " 12  slope       6492 non-null   float64 \n",
      " 13  age         6763 non-null   float64 \n",
      "dtypes: bool(3), category(4), float64(7)\n",
      "memory usage: 422.0 KB\n"
     ]
    }
   ],
   "source": [
    "hd_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Duplicated Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train/Test split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocessing Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Conclusions and results**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
